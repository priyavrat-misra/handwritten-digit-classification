{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import device, get_num_correct, RunBuilder\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and transform the data\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "# load the test set\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hyper-parameter search\n",
    "from collections import OrderedDict\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.003, 0.001, 0.0003],\n",
    "    batch_size = [256, 512]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# iterate through the cross product of hyper-parameters defined in params\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    network = Network().to(device)  # initialize the NN\n",
    "\n",
    "    # load the train set\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=run.batch_size, shuffle=True, num_workers=1)\n",
    "    # specify the optimizer\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    # comment will be used for naming the runs based on each run's hyper-parameters\n",
    "    comment = f'-{run}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "\n",
    "    # number of epochs used for training\n",
    "    num_epochs = 4\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        # these will be used to track the running loss and correct so far\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        network.train()  # set the model to train mode\n",
    "        for batch in train_loader:\n",
    "            # load the batch to the available device (cpu/gpu)\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "            # forward pass: compute predicted outputs by passing the batch to the models\n",
    "            preds = network(images)\n",
    "            # calculate the loss\n",
    "            loss = criterion(preds, labels)\n",
    "            # clear the accumulated gradients from the previous pass\n",
    "            optimizer.zero_grad()\n",
    "            # backward pass: compute gradient of the loss wrt model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update the running loss\n",
    "            train_loss += loss.item() * run.batch_size\n",
    "            # update the running num of correct\n",
    "            train_correct += get_num_correct(preds, labels)\n",
    "\n",
    "\n",
    "        # add the train loss for the current epoch to tensorboard\n",
    "        tb.add_scalar('Train Loss', train_loss, epoch)\n",
    "        # add the train accuracy for the current epoch to tensorboard\n",
    "        tb.add_scalar('Train Accuracy', train_correct / len(train_set), epoch)\n",
    "        \n",
    "        ##################\n",
    "        # test the model #\n",
    "        ##################\n",
    "        network.eval()  # set the model to evaluation mode\n",
    "        # turn off the grad tracking feature as we don't need gradients for validation or testing\n",
    "        with torch.no_grad():\n",
    "\n",
    "            test_loss = 0\n",
    "            test_correct = 0\n",
    "            # these will be used to track the running loss and correct so far\n",
    "\n",
    "            for batch in test_loader:\n",
    "                # load the batch to the available device (cpu/gpu)\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)\n",
    "                # forward pass: compute predicted outputs by passing the batch to the models\n",
    "                preds = network(images)\n",
    "                # calculate the loss\n",
    "                loss = criterion(preds, labels)\n",
    "\n",
    "                # update the running loss\n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                # update the running num of correct\n",
    "                test_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            # add the test loss for the current epoch to tensorboard\n",
    "            tb.add_scalar('Test Loss', test_loss, epoch)\n",
    "            # add the test accuracy for the current epoch to tensorboard\n",
    "            tb.add_scalar('Test Accuracy', test_correct / len(test_set), epoch)\n",
    "\n",
    "\n",
    "        # iterate through parameter's weights and it's grads and plot their histograms to tensorboard\n",
    "        # this is pretty helpful when checking if the model is facing vanishing gradients problem \n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "\n",
    "    # save the model\n",
    "    torch.save(network.state_dict(), f'./models/without_validation/model-{run}.ckpt')"
   ]
  },
  {
   "source": [
    "__Note:__ this project uses Tensorboard as an evaluation utility for plotting running losses, accuracies, histograms etc. So if you are wondering why there are no outputs while the network is training, use Tensorboard (_open terminal, change path to project's repo and run this command `tensorboard --logdir=runs`_)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}